{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd66c44-29fc-4a56-ab03-e59f4c7ae63c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from time import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from osgeo import gdal\n",
    "\n",
    "import multiprocessing as mp\n",
    "\n",
    "import rioxarray as rxr\n",
    "from numba import njit\n",
    "\n",
    "from bokeh.plotting import figure, show\n",
    "from bokeh.models import ColumnDataSource, Whisker\n",
    "from bokeh.io import output_notebook\n",
    "from bokeh.palettes import Colorblind3\n",
    "# from bokeh.layouts import gridplot, row, column\n",
    "output_notebook()\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ed0062-89d5-451f-b4a5-be83bf21bf03",
   "metadata": {},
   "outputs": [],
   "source": [
    "from whitebox.whitebox_tools import WhiteboxTools\n",
    "\n",
    "wbt = WhiteboxTools()\n",
    "wbt.verbose = False\n",
    "# wbt.verbose = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1723aa48-bd22-4a92-a3a6-1ab86a22e2ab",
   "metadata": {},
   "source": [
    "## Evaluate the effect of dem resolution on basin representation and attribute estimation\n",
    "\n",
    "As the basin scale decreases, methodological choices begin to have a significant impact on the number of cells captured and used to represent a basin. In addition, some attributes are affected by DEM resolution, in particular terrain attributes.  Here we investigate two examples. \n",
    "\n",
    "Consider a square grid intersected by an arbitrary curvilinear loop.  If we color the grid cells intersected by the line red, and we colour any cell inside the closed loop blue, let $P_{edge}$ the percentage of edge cells be the number of red cells divided by the number of red plus blue cells.\n",
    "\n",
    "Now if we hold the loop constant and change the grid cell dimension $d_{grid}$, intuitively $P_{edge}$ will increase as the grid cell size increases since eventually the loop will be encompassed by a single grid cell.  $P_{edge}$ will approach 1 as $d_{grid}$ increases.\n",
    "\n",
    "When we extract basin attributes from a geospatial raster using a basin polygon, at what point does a choice affecting the number of edge pixels become significant?  At some combination of raster resolution and basin size, the proportion of edge pixels will be significant.  The purpose of this exercise is to compare DEM datasets of two different resolutions to get a sense of the basin size at which the edge pixel method chosen becomes significant to the representativeness of the sample of raster pixels used to compute basin attributes.\n",
    "\n",
    "## tl;dr\n",
    "\n",
    "Compare 30m vs. 90m dem using a large sample of basin polygons over a wide scale to see when the basin is mostly edge pixels that are either included or excluded depending upon the clipping method.\n",
    "\n",
    "Once the basin clipping is done, the mean slope is computed for each basin from two different DEM sources to compare the effect of DEM resolution on mean basin slope calculation.\n",
    "\n",
    "## Method\n",
    "\n",
    "The method is as follows:\n",
    "1. Select a random sample of 10k basin polygons from the BCUB polygon set.\n",
    "2. Use each polygon as a clipping mask and create a temporary clipped DEM to represent the basin pixels. Save these as temporary files because they will be ingested by Whiteboxtools \"Slope\" tool in the subsequent slope comparison.\n",
    "3. For each clipped raster:    \n",
    "   a. Find all non-Nan indices in the clipped raster.  An edge pixel is one which has at least one NaN neighbour.  \n",
    "   b. Count all edge pixels and divide by the total number of non-NaN indices.  \n",
    "   c. The process assumes there are no data gaps in the basin prior to clipping.  This is checked by first counting NaN values for pixels within the polygon and asserting equal to zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "787ce129-b79d-40e4-9cdf-f75cf03344e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = os.path.dirname(os.getcwd())\n",
    "DATA_DIR = os.path.join(BASE_DIR, 'processed_data')\n",
    "# HYSETS_DIR = os.path.join(BASE_DIR, '/home/danbot2/code_5820/large_sample_hydrology/common_data/HYSETS_data/'\n",
    "\n",
    "# This assumes you've downloaded a basin polygon set \n",
    "# and have processed the DEM for the same region \n",
    "# with both the 3DEP and EENV DEM\n",
    "# here we'll do it for 08D (central coast)\n",
    "region_code = 'FRA'\n",
    "BASIN_DIR = os.path.join(DATA_DIR, 'basin_attributes/polygons')\n",
    "\n",
    "# update with the path of processed DEM\n",
    "# these scripts would be already run in the dataset replication\n",
    "# see the following scripts in setup_scripts/\n",
    "#     * get_3DEP_DEM.py   <--retrieves the USGS 3DEP dem\n",
    "#     * get_EENV_DEM.py   <--retrieves the EarthEnv 90m dem\n",
    "#     * clip_region_DEM.py <-- takes the assembled tiles and creates \n",
    "\n",
    "DEM_PATH = '/home/danbot2/code_5820/large_sample_hydrology/common_data/DEM_data/processed_dem/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8719fc1c-3f1b-4504-abce-817fe2b85791",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_folder = os.path.join(BASE_DIR, 'validation/tmp')\n",
    "tmp_basins = os.path.join(temp_folder, 'basin_polygons/')\n",
    "\n",
    "if not os.path.exists(tmp_basins):\n",
    "    os.makedirs(tmp_basins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a9bbaa-48e9-46ed-ba9a-eb120e6e44af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_slope_on_region_raster(region_code, DEM_source):\n",
    "    if region_code == 'FRA':\n",
    "        region_code = 'Fraser'\n",
    "    src_dem_fname = f'{DEM_source}/{region_code}_EENV_DEM_3005_res1.tif'\n",
    "    if 'USGS' in src:\n",
    "        src_dem_fname = f'{DEM_source}/{region_code}_{DEM_source}_3005_res1.tif'\n",
    "    # compute the mean slope of the clipped basin raster\n",
    "    output_fname = src_dem_fname.replace('res1.tif', 'slope.tif')\n",
    "    output_fpath = os.path.join(DEM_PATH, output_fname)\n",
    "    region_fpath = os.path.join(DEM_PATH, src_dem_fname)\n",
    "    if not os.path.exists(output_fpath):\n",
    "        wbt.slope(\n",
    "            region_fpath, \n",
    "            output_fpath, \n",
    "            zfactor=None, \n",
    "            units=\"degrees\", \n",
    "            callback=None\n",
    "        )\n",
    "   \n",
    "    return output_fpath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd946c8-e17f-43d8-8955-c2732badbe9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "region_slope_paths = []\n",
    "for src in ['EENV_DEM90', 'USGS_3DEP']:\n",
    "    region_slope_path = compute_slope_on_region_raster(region_code, src)\n",
    "    region_slope_paths.append(region_slope_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8262330-c76c-4060-9074-bc4edcc78172",
   "metadata": {},
   "outputs": [],
   "source": [
    "geom_fpath = f'{region_code}_basin_geometries.parquet'\n",
    "df = gpd.read_parquet(os.path.join(BASIN_DIR, geom_fpath))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a50fda-6dd5-4541-96b4-d36fedca3f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select a random subset of 10K basin polygons\n",
    "select_new = False\n",
    "sample_size  = 1e4\n",
    "\n",
    "if select_new:    \n",
    "    ids = np.random.choice(df['id'].values, size=int(sample_size), replace=False)\n",
    "    print(len(ids))\n",
    "else:\n",
    "    existing_basin_files = os.listdir(os.path.join(temp_folder, 'basin_polygons'))\n",
    "    ids = sorted(list(set([e.split('_')[1] for e in existing_basin_files])))\n",
    "    print(f'{len(ids)} existing basin ids to process')\n",
    "    if len(ids) < sample_size:\n",
    "        sample_size  = 1e4\n",
    "        add_ids = np.random.choice(df['id'].values, size=int(sample_size - len(ids)), replace=False)\n",
    "        assert all([e not in ids for e in add_ids])\n",
    "        ids += [str(e) for e in add_ids]\n",
    "        print(f'{len(ids)} existing basin ids to process')\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d47de8e5-2fc4-45e9-af83-c8644e14fe43",
   "metadata": {},
   "source": [
    "## Clip the DEM with each polygon and create temporary raster files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7c0999-c6fd-4703-b429-a70cf88f4b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_raster(fpath):\n",
    "    rds = rxr.open_rasterio(fpath, masked=True, mask_and_scale=True)\n",
    "    crs = rds.rio.crs\n",
    "    affine = rds.rio.transform(recalc=False)\n",
    "    return rds, crs, affine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d38e9bcd-ec1e-4daf-9d93-2314134a6978",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clip_rasters(input):\n",
    "    basin_id, polygon, DEM_source, buffer, region_code, temp_folder = input\n",
    "    \n",
    "    dem_fpath = os.path.join(DEM_PATH, f'{DEM_source}/{region_code}_USGS_3DEP_3005_res1.tif')\n",
    "    rc = region_code\n",
    "    if region_code == 'FRA':\n",
    "        rc = 'Fraser'\n",
    "    src_dem_fname = f'{DEM_source}/{rc}_EENV_DEM_3005_res1.tif'\n",
    "    if 'USGS' in src:\n",
    "        src_dem_fname = f'{DEM_source}/{rc}_{DEM_source}_3005_res1.tif'\n",
    "        \n",
    "    input_raster_path = os.path.join(DEM_PATH, src_dem_fname)\n",
    "    # if you want to test the effect of adding a buffer to the polygon\n",
    "    if buffer != 0:\n",
    "        dem, crs_obj, affine = retrieve_raster(dem_fpath)\n",
    "        res = dem.rio.resolution()\n",
    "        if buffer == 1:\n",
    "            buff = np.sqrt(res[0]**2 + res[1]**2)\n",
    "        elif buffer == 2:\n",
    "            buff = max(abs(res[0]), abs(res[1]))\n",
    "        bdf = bdf.buffer(buff)\n",
    "\n",
    "    # save the polygon to a temp file\n",
    "    crs = 3005\n",
    "    basin_fname = f'basin_polygons/basin_{basin_id:05d}_b{buffer}_{crs}.shp'\n",
    "    basin_fpath = os.path.join(temp_folder, basin_fname)\n",
    "    if not os.path.exists(basin_fpath):  \n",
    "        basin_data = {\n",
    "            'id': [basin_id], \n",
    "            'region_code': [region_code]\n",
    "        }\n",
    "        bdf = gpd.GeoDataFrame(basin_data, geometry=[polygon], crs=crs)   \n",
    "        geom_type = bdf.geometry.values[0].geom_type\n",
    "\n",
    "        if geom_type != 'Polygon':\n",
    "            print(f'geom is {geom_type}')\n",
    "            if geom_type == 'GeometryCollection':\n",
    "                foo = gpd.GeoDataFrame(geometry=[polygon], crs=3005)\n",
    "                bdf = foo.dissolve()                \n",
    "                geom_type = bdf.geometry.values[0].geom_type\n",
    "                bdf.to_file(basin_fpath)\n",
    "            elif geom_type == 'MultiPolygon':\n",
    "                print(f'multipolygon found: {basin_fpath}')\n",
    "                bdf = gpd.GeoDataFrame(geometry=[polygon], crs=3005)\n",
    "                bdf = bdf.explode(index_parts=False)\n",
    "                bdf['area'] = bdf.geometry.area\n",
    "                bdf = bdf[bdf['area'] >= 2E3]\n",
    "                if len(bdf) == 0:\n",
    "                    print(f'no polygon found {basin_fpath}')\n",
    "                    raise Exception('no geoms left!!')      \n",
    "                elif len(bdf) == 1:\n",
    "                    bdf.to_file(basin_fpath)\n",
    "                else:\n",
    "                    raise Exception('too many geoms!!')  \n",
    "                geom_type = bdf.geometry.values[0].geom_type\n",
    "            if geom_type != 'Polygon':\n",
    "                raise Exception('fix geom type!!')\n",
    "        else:\n",
    "            if not os.path.exists(basin_fpath):\n",
    "                bdf.to_file(basin_fpath)\n",
    "\n",
    "    # Clip the raster using the saved basin polygon\n",
    "    raster_fname = f\"{DEM_source}/{int(basin_id):05}_clipped_{buffer}mbuff.tif\"\n",
    "    fpath_out = os.path.join(temp_folder, raster_fname)\n",
    "    if not os.path.exists(fpath_out):\n",
    "        g = gdal.Warp(fpath_out, input_raster_path, format=\"GTiff\",\n",
    "                      cutlineDSName=basin_fpath,\n",
    "                      cropToCutline=True)\n",
    "        g = None \n",
    "\n",
    "    return (fpath_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "058cf8d5-097b-4e75-9b9d-a3a62c94db17",
   "metadata": {},
   "outputs": [],
   "source": [
    "tstart = time()\n",
    "buffer = 0\n",
    "# get all the ids\n",
    "failed_ids = []\n",
    "edge_dict = {}\n",
    "\n",
    "n = 0\n",
    "for src in ['USGS_3DEP', 'EENV_DEM90']:\n",
    "    tmp_raster_folder = os.path.join(temp_folder, src)\n",
    "    if not os.path.exists(tmp_raster_folder):\n",
    "        os.mkdir(tmp_raster_folder)\n",
    "    t1 = time()\n",
    "    selected_df = df[df['id'].isin(ids)].copy()\n",
    "    print(f'{len(selected_df)} items selected for processing')\n",
    "    inputs = list(selected_df.itertuples(index=False, name=None))\n",
    "    # additional input parameters\n",
    "    inputs = [e + (src, buffer, region_code, temp_folder) for e in inputs]\n",
    "    print(f'Processing {len(inputs)} with {src} DEM')\n",
    "\n",
    "    # clip the dems to all basin polygons\n",
    "    n_procs = 6\n",
    "    p = mp.Pool(n_procs)\n",
    "    print('Starting raster clipping:')\n",
    "    clip_fpaths = p.map(clip_rasters, inputs)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae42c75-1c87-4f54-bac4-7bae46a6dd5e",
   "metadata": {},
   "source": [
    "## Count Perimeter Cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d9c843e-7a9b-4c65-aa7d-df97669af5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit\n",
    "def edge_pixel_proportion(m):\n",
    "    \"\"\"\n",
    "    The input m is a matrix representing the dem\n",
    "    where the only nonzero values are indices that\n",
    "    lie inside the basin.  \n",
    "    Count the cells that have at least one NaN neighbour\n",
    "    and compare to the total number of numeric cells.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get the number of rows and columns in the matrices\n",
    "    # rows, cols = m1.shape\n",
    "    (r1, c1) = m.shape\n",
    "    # print(r1, c1)\n",
    "\n",
    "    dem_px = 0\n",
    "    edge_px = 0\n",
    "\n",
    "    # Count non-zero elements in matrix\n",
    "    for row in range(r1):\n",
    "        for col in range(c1):\n",
    "            if ~np.isnan(m[row, col]):\n",
    "                dem_px += 1\n",
    "                # check all neighbouring cells if any are nan\n",
    "                indices = [(row - 1, col - 1), (row - 1, col), (row - 1, col + 1),\n",
    "                           (row, col-1), (row, col + 1),\n",
    "                           (row + 1, col-1), (row + 1, col), (row + 1, col + 1)]\n",
    "                nan_nbr = False\n",
    "                for r, c in indices:\n",
    "                    if (r <= r1 - 1) & (r >= 0) & (c >= 0) & (c <= c1 - 1):\n",
    "                        if np.isnan(m[r, c]):\n",
    "                            edge_px += 1\n",
    "                            break\n",
    "    \n",
    "    # Return the proportion of edge pixels\n",
    "    if dem_px == 0:\n",
    "        return 0\n",
    "    return edge_px / dem_px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c3eca6-3c98-4809-ae7d-a4f366a2e1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_basin_raster(f):\n",
    "    basin_id = int(f.split('/')[-1].split('_')[0])\n",
    "    raster, crs, affine = retrieve_raster(f)\n",
    "    data = raster.data[0]\n",
    "    pct_edge_px = edge_pixel_proportion(raster.data[0])\n",
    "    return (basin_id, pct_edge_px)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f2c2b8-93a9-413d-86f4-86481e8852d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "perimeter_results = {}\n",
    "for src in ['EENV_DEM90', 'USGS_3DEP']:\n",
    "    tmp_raster_folder = os.path.join(temp_folder, src)\n",
    "    t1 = time()\n",
    "    # additional input parameters\n",
    "    raster_files = os.listdir(os.path.join(BASE_DIR, f'validation/tmp/{src}'))\n",
    "    raster_paths = [os.path.join(tmp_raster_folder, r) for r in raster_files]\n",
    "\n",
    "    # you may run into RAM issues if you parallelize this step\n",
    "    perimeter_results[src] = []\n",
    "    n = 0\n",
    "    for f in sorted(raster_paths):\n",
    "        n += 1\n",
    "        result = process_basin_raster(f)\n",
    "        perimeter_results[src].append(result)\n",
    "\n",
    "    t2 = time()\n",
    "    ut = len(raster_paths) / (t2-t1)\n",
    "    print(f'{len(raster_paths)} {src} basins processed in {t2-t1:.0f}s ({ut:.1f}/s)')\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a677fb-8e6c-48c8-8a45-3eee0c9a965f",
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_dfs = []\n",
    "for src in ['EENV_DEM90', 'USGS_3DEP']:\n",
    "    edge_df = pd.DataFrame(perimeter_results[src])\n",
    "    edge_df.columns = ['basin_id', f'pct_edge_cells_{src}']\n",
    "    edge_df.set_index('basin_id', inplace=True)\n",
    "    edge_dfs.append(edge_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be456b9-f6ef-4a03-858d-e0f9817d9e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(edge_dfs)):\n",
    "    edge_dfs[i] = edge_dfs[i][~edge_dfs[i].index.duplicated(keep='first')]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f529628-a5ad-474c-b460-82034ca397d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.concat(edge_dfs, join='inner', axis=1)\n",
    "result['area'] = [df.loc[df['id'] == i, 'basin'].area.values[0] / 1e6 for i in result.index.values]\n",
    "print(len(result))\n",
    "result.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6adb63a9-1972-4c1d-ba26-c3d716c19a75",
   "metadata": {},
   "source": [
    "## Plot Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ad2d06-b9b5-4de6-ac7f-6291bcb340f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def equiprobable_binning(data, param1, param2, samples_per_bin):\n",
    "    # group deviation values by perimeter bin number\n",
    "    df = data.copy()\n",
    "    n_bins = int(len(df)/samples_per_bin)\n",
    "    print(f'   Creating {n_bins} bins of {samples_per_bin} samples/bin (N={n_bins* samples_per_bin})')\n",
    "    \n",
    "    qc, edges = pd.qcut(df[param1], q=n_bins, precision=3, retbins=True)\n",
    "    edges1 = edges[1:]\n",
    "    \n",
    "    df['p_bin'] = np.digitize(df[param1], bins=edges1, right=True)\n",
    "    \n",
    "    bin_widths = [j-i for i, j in zip(edges[:-1], edges[1:])] \n",
    "    bin_centres = [(j+i)/2 for i, j in zip(edges[:-1], edges[1:])]\n",
    "    evs = df[[param1, param2, 'p_bin']].groupby('p_bin').mean()\n",
    "\n",
    "    evs['bin_width'] = bin_widths\n",
    "    evs['bin_centre'] = (edges[1:] + edges[:-1]) / 2\n",
    "    # evs['edges'] = edges\n",
    "    evs['ubnd'] = df[[param1, param2, 'p_bin']].groupby('p_bin').quantile(0.95)[param2]\n",
    "    evs['lbnd'] = df[[param1, param2, 'p_bin']].groupby('p_bin').quantile(0.05)[param2]\n",
    "    evs['q1'] = df[[param1, param2, 'p_bin']].groupby('p_bin').quantile(0.25)[param2]\n",
    "    evs['q3'] = df[[param1, param2, 'p_bin']].groupby('p_bin').quantile(0.75)[param2]\n",
    "    evs['median'] = df[[param1, param2, 'p_bin']].groupby('p_bin').quantile(0.5)[param2]\n",
    "    evs['mean'] = df[[param1, param2, 'p_bin']].groupby('p_bin').mean()[param2]\n",
    "    evs.loc[0, 'ubnd'] = evs.loc[1, 'ubnd']\n",
    "    evs.loc[0, 'lbnd'] = evs.loc[1, 'lbnd']        \n",
    "    return evs, edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f34ffac-ea6e-4643-ad7e-83d7dcf2f474",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binned_fig(fig, src, df, samples_per_bin):\n",
    "    edge_pct = f'pct_edge_cells_{src}'\n",
    "    evs, edges = equiprobable_binning(df, 'area', edge_pct, 600)\n",
    "    \n",
    "    linetype = 'dashed'\n",
    "    color = Colorblind3[0]\n",
    "    color2 = Colorblind3[0]\n",
    "    label = '90m'\n",
    "    if src == 'USGS_3DEP':\n",
    "        label = '30m'\n",
    "        color = 'black'\n",
    "        linetype = 'dotted'\n",
    "        color2 = 'black'\n",
    "    \n",
    "    fig.toolbar.autohide = True\n",
    "    \n",
    "    classes = evs['bin_centre'].values\n",
    "    ub = evs['ubnd'].values\n",
    "    lb = evs['lbnd'].values\n",
    "    source = ColumnDataSource(data=dict(base=classes, upper=ub, lower=lb))\n",
    "    \n",
    "    # outlier range\n",
    "    w = Whisker(base='base', upper=\"upper\", lower=\"lower\", source=source,\n",
    "                     line_color=color, line_alpha=0.8, line_width=1)\n",
    "    w.upper_head.line_color = color\n",
    "    w.lower_head.line_color = color\n",
    "\n",
    "    if src == 'USGS_3DEP':\n",
    "        fig.circle(evs['bin_centre'], evs['median'], \n",
    "                color=color2, size=5, fill_alpha=0,\n",
    "                   legend_label=f'bin median {label}')    \n",
    "    else:\n",
    "        fig.square(evs['bin_centre'], evs['median'], \n",
    "                color=color2, size=5,\n",
    "                   legend_label=f'bin median {label}')    \n",
    "        \n",
    "    fig.add_layout(w)\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e5330f-73c6-49c2-822b-dedca7169590",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = figure(width=500, height=400, title=f\"\", y_range=(0, 0.5),\n",
    "           toolbar_location='above', x_axis_type='log')\n",
    "\n",
    "for src in ['EENV_DEM90', 'USGS_3DEP']:\n",
    "    fig = binned_fig(fig, src, result, 600)\n",
    "    \n",
    "fig.xaxis.axis_label = 'Drainage Area [km²]'\n",
    "fig.yaxis.axis_label = 'Proportion of cells at edge'\n",
    "# fig.grid.visible = False\n",
    "show(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "275e054a-85f3-469d-86c4-252efee95d4f",
   "metadata": {},
   "source": [
    "## Compute mean basin slope\n",
    "\n",
    "At the beginning of this notebook we processed the slope for the full region.  Here we compute the mean slope for each basin using basin polygons as clipping masks and compare 30 and 90m dem sources to see the effect on a large sample of basins.\n",
    "\n",
    "**NOTE**\n",
    "\n",
    "In this example we use a random sample of 10K basins from the Frasier basin, extracted from the basin geometry file.  Note that the figure in the associated paper draws a random sample of 10K basins from the full study region.  In hindsight, it should have been seeded such that the figure could be replicated precisely.  It was not done, however at the bottom of this is a text output of the list of basin IDs so the figure below can at least be replicated. \n",
    "\n",
    "The distribution of basin slopes will vary based on the random sample drawn, but the point of the exercise is to show that the lower resolution DEM tends to compute lower slopes for the same basin, and this trend holds across all samples.  One limitation of the comparison is that we use the basin polygon derived from the higher resolution DEM, and we do not check to see if the lower resolution stream network identifies the same stream network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87fe44f5-80aa-4afd-80fe-4022a9512251",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clip_slope_raster(input):\n",
    "    basin_id, buffer, crs, input_raster_fpath, DEM_source = input\n",
    "    basin_fname = f'basin_polygons/basin_{basin_id:05d}_b{buffer}_{crs}.shp'\n",
    "    basin_fpath = os.path.join(temp_folder, basin_fname)\n",
    "    if not os.path.exists(basin_fpath):\n",
    "        print('{basin_fpath.split(\"/\")[-1]} not found.  Saving polygon.')\n",
    "        basin = df[df['id'] == basin_id].copy()\n",
    "        basin.to_file(basin_fpath)\n",
    "        print('    ...saved')\n",
    "\n",
    "    # Clip the raster using the saved basin polygon\n",
    "    raster_fname = f\"{DEM_source}/{int(basin_id):05}_clipped_slope_{buffer}mbuff.tif\"\n",
    "    fpath_out = os.path.join(temp_folder, raster_fname)\n",
    "    if not os.path.exists(fpath_out):\n",
    "        g = gdal.Warp(fpath_out, input_raster_fpath, format=\"GTiff\",\n",
    "                      cutlineDSName=basin_fpath,\n",
    "                      cropToCutline=True)\n",
    "        g = None \n",
    "    return fpath_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd13f4c-d5f8-4e2a-9e9a-eba92d7ee4a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ','.join(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be4fd3f9-408d-4e7b-9c15-904deafeff76",
   "metadata": {},
   "outputs": [],
   "source": [
    "slope_df = pd.DataFrame()\n",
    "n = 0\n",
    "for src in ['EENV_DEM90', 'USGS_3DEP']:\n",
    "    input_raster_fpath = [e for e in region_slope_paths if src in e][0]\n",
    "    slope_inputs = [(int(id), buffer, 3005, input_raster_fpath, src) for id in ids] \n",
    "    # compute slope\n",
    "    p = mp.Pool(n_procs)\n",
    "    slope_paths = p.map(clip_slope_raster, slope_inputs)\n",
    "    for path in slope_paths:\n",
    "        # slope_path = clip_slope_raster(inp)\n",
    "         # retrieve the slope raster and compute mean basin slope\n",
    "        raster, _, _ = retrieve_raster(path)\n",
    "        mean_slope = np.nanmean(raster.data[0])        \n",
    "        # basin id is the index in the result dataframe, so update a 'mean slope' column\n",
    "        basin_id = path.split('/')[-1].split('_')[0]\n",
    "        slope_df.loc[basin_id, src] = np.nanmean(raster.data[0])\n",
    "        if n % 500 == 0:\n",
    "            print(f'processed {n}/{len(ids)} basins')\n",
    "        n += 1\n",
    "    n = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9007746-8ab9-45c5-bbf2-3d9e9d1af347",
   "metadata": {},
   "outputs": [],
   "source": [
    "slope_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "949be0ef-e6f4-4c98-a187-d532c7ea7481",
   "metadata": {},
   "outputs": [],
   "source": [
    "foo = slope_df[slope_df[['EENV_DEM90', 'USGS_3DEP']].isna().any(axis=1)]\n",
    "\n",
    "slope_df.dropna(inplace=True, how='any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b675e42e-f708-4d19-ad1c-ac8a6523f8a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ph1 = figure(title=f'', toolbar_location=None, \n",
    "             width=400, height=300)#, x_range=fig1.x_range)\n",
    "\n",
    "hhist1, hedges1 = np.histogram(slope_df['EENV_DEM90'].values, bins=20, density=True)\n",
    "hhist2, hedges2 = np.histogram(slope_df['USGS_3DEP'].values, bins=hedges1, density=True)\n",
    "\n",
    "ph1.xgrid.grid_line_color = None\n",
    "ph1.yaxis.major_label_orientation = np.pi/4\n",
    "ph1.background_fill_color = \"#fafafa\"\n",
    "ph1.yaxis.axis_label = 'P(X)'\n",
    "ph1.xaxis.axis_label = 'Mean Slope [deg]'\n",
    "\n",
    "ph1.quad(bottom=0, left=hedges1[:-1], right=hedges1[1:], top=hhist1, legend_label='90m', \n",
    "                  line_alpha=0.6, fill_alpha=0.5, color=Colorblind3[0], line_color=\"#3A5785\")\n",
    "# hh1 = ph1.quad(bottom=0, left=hedges1[:-1], right=hedges1[1:], top=hzeros1, alpha=0.5, **LINE_ARGS)\n",
    "\n",
    "ph1.quad(bottom=0, left=hedges2[:-1], right=hedges2[1:], top=hhist2, legend_label='30m',\n",
    "                  line_alpha=0.6, fill_alpha=0.5, color=Colorblind3[2], line_color=\"#3A5785\")\n",
    "# hh11 = ph1.quad(bottom=0, left=hedges2[:-1], right=hedges2[1:], top=hzeros2, alpha=0.5, **LINE_ARGS)\n",
    "# hh2 = ph.quad(bottom=0, left=hedges[:-1], right=hedges[1:], top=hzeros, alpha=0.1, **LINE_ARGS)\n",
    "# hh2 = ph.quad(bottom=0, left=hedges[:-1], right=hedges[1:], top=hzeros, alpha=0.1, **LINE_ARGS)\n",
    "ph1.toolbar_location = 'right'\n",
    "ph1.toolbar.autohide = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78fc6d61-ecee-44d1-8c25-e4cdeb6c2188",
   "metadata": {},
   "outputs": [],
   "source": [
    "# layout = column(ph1)\n",
    "show(ph1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93406ae6-fd10-4876-a151-27de6d073fc5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
